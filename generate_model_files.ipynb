{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2efb963d-e1f4-4899-887a-b3530d5125e7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Introduction\n",
    "In this script, we will generate the model files for the multiple scenarios we would like to simulate, which in this case are:\n",
    "\n",
    "- Fluvial flooding (Q100) – Baseline\n",
    "- Fluvial flooding (Q1000) – Baseline\n",
    "- Fluvial flooding (Q100) – SSP5 2030\n",
    "- Fluvial flooding (Q1000) – SSP5 2030\n",
    "- Pluvial flooding (Q100) – Baseline\n",
    "- Pluvial flooding (Q1000) – Baseline\n",
    "- Pluvial flooding (Q100) – SSP5 2030\n",
    "- Pluvial flooding (Q1000) – SSP5 2030\n",
    "- Pluvial flooding + Fluvial flooding (Q100) – Baseline\n",
    "- Pluvial flooding + Fluvial flooding (Q1000) – Baseline\n",
    "- Pluvial flooding + Fluvial flooding (Q100) – SSP5 2030\n",
    "- Pluvial flooding + Fluvial flooding (Q1000) – SSP5 2030\n",
    "- Pluvial flooding + Fluvial flooding (Q1000) – SSP5 2050\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f80e12f6-8bc3-49f6-9633-2ae5fade11d2",
   "metadata": {},
   "source": [
    "# Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "756b69e5-7254-4121-96af-4e60b7546996",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-20T09:57:03.282834Z",
     "iopub.status.busy": "2024-03-20T09:57:03.280515Z",
     "iopub.status.idle": "2024-03-20T09:57:03.313878Z",
     "shell.execute_reply": "2024-03-20T09:57:03.312892Z",
     "shell.execute_reply.started": "2024-03-20T09:57:03.282786Z"
    }
   },
   "outputs": [],
   "source": [
    "from hydromt.config import configread\n",
    "import glob\n",
    "import os\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "73cfb1f3-b184-44d0-825a-736886a81ca2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-20T09:57:03.619789Z",
     "iopub.status.busy": "2024-03-20T09:57:03.618843Z",
     "iopub.status.idle": "2024-03-20T09:57:03.647050Z",
     "shell.execute_reply": "2024-03-20T09:57:03.645704Z",
     "shell.execute_reply.started": "2024-03-20T09:57:03.619747Z"
    }
   },
   "outputs": [],
   "source": [
    "root = '/Users/aprida/Documents/Consulting/Private_sector/Keolis/Model_Alvaro'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6998a814-b1e2-424f-932e-23c0800db789",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "39b7f51a-924b-43da-a6bc-f36511d49f22",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-20T09:57:04.069320Z",
     "iopub.status.busy": "2024-03-20T09:57:04.067155Z",
     "iopub.status.idle": "2024-03-20T09:57:04.097176Z",
     "shell.execute_reply": "2024-03-20T09:57:04.096567Z",
     "shell.execute_reply.started": "2024-03-20T09:57:04.068181Z"
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "def convert_paths_to_strings(data):\n",
    "    if isinstance(data, dict):\n",
    "        return {key: convert_paths_to_strings(value) for key, value in data.items()}\n",
    "    elif isinstance(data, list):\n",
    "        return [convert_paths_to_strings(item) for item in data]\n",
    "    elif isinstance(data, Path):\n",
    "        return str(data)\n",
    "    else:\n",
    "        return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7af4e87-af1d-4670-a0f0-8e2e677b2d1e",
   "metadata": {},
   "source": [
    "# Generate scenario files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "2a54741e-cf2c-4591-a512-ab16f01b803f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-20T09:57:04.597896Z",
     "iopub.status.busy": "2024-03-20T09:57:04.597281Z",
     "iopub.status.idle": "2024-03-20T09:57:04.630619Z",
     "shell.execute_reply": "2024-03-20T09:57:04.629728Z",
     "shell.execute_reply.started": "2024-03-20T09:57:04.597855Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PL_rp100_24H_baseline.csv',\n",
       " 'PL_rp1000_24H_baseline.csv',\n",
       " 'PL_rp100_24H_2030_ssp585.csv',\n",
       " 'PL_rp1000_24H_2030_ssp585.csv',\n",
       " 'FL_rp100_baseline.csv',\n",
       " 'FL_rp1000_baseline.csv',\n",
       " 'FL_rp100_2030_ssp585.csv',\n",
       " 'FL_rp1000_2030_ssp585.csv',\n",
       " ['PL_rp100_24H_baseline.csv', 'FL_rp100_baseline.csv'],\n",
       " ['PL_rp1000_24H_baseline.csv', 'FL_rp1000_baseline.csv'],\n",
       " ['PL_rp100_24H_2030_ssp585.csv', 'FL_rp100_2030_ssp585.csv'],\n",
       " ['PL_rp1000_24H_2030_ssp585.csv', 'FL_rp1000_2030_ssp585.csv'],\n",
       " ['PL_rp1000_24H_2050_ssp585.csv', 'FL_rp1000_2050_ssp585.csv']]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define scenarios to model\n",
    "\n",
    "scenarios = [\n",
    "    'PL_rp100_24H_baseline',\n",
    "    'PL_rp1000_24H_baseline',\n",
    "    'PL_rp100_24H_2030_ssp585',\n",
    "    'PL_rp1000_24H_2030_ssp585',\n",
    "    'FL_rp100_baseline',\n",
    "    'FL_rp1000_baseline',\n",
    "    'FL_rp100_2030_ssp585',\n",
    "    'FL_rp1000_2030_ssp585',\n",
    "    'PLFL_rp100_baseline',\n",
    "    'PLFL_rp1000_baseline',\n",
    "    'PLFL_rp100_2030_ssp585',\n",
    "    'PLFL_rp1000_2030_ssp585',\n",
    "    'PLFL_rp1000_2050_ssp585'\n",
    "]\n",
    "\n",
    "# Generate scenario file names\n",
    "scenario_files = []\n",
    "\n",
    "for scenario in scenarios:\n",
    "\n",
    "    flood_type = scenario.split('_')[0]\n",
    "    rp = scenario.split('_')[1].split('rp')[1]\n",
    "    ssp = scenario.split('_')[-1]\n",
    "\n",
    "    if flood_type == 'PL':\n",
    "        time_horizon = scenario.split('_')[3]\n",
    "        tmp = f'{flood_type}_rp{rp}_24H_{time_horizon}.csv' if time_horizon == 'baseline' else f'{flood_type}_rp{rp}_24H_{time_horizon}_{ssp}.csv'\n",
    "    \n",
    "    elif flood_type == 'FL':\n",
    "        time_horizon = scenario.split('_')[2]\n",
    "        tmp = f'{flood_type}_rp{rp}_{time_horizon}.csv' if time_horizon == 'baseline' else f'{type}_rp{rp}_{time_horizon}_{ssp}.csv'\n",
    "    \n",
    "    else:\n",
    "        tmp = []\n",
    "        flood_type = ['PL', 'FL']\n",
    "        time_horizon = scenario.split('_')[2]\n",
    "        for type in flood_type:\n",
    "            \n",
    "            if type == 'PL':\n",
    "                file = f'{type}_rp{rp}_24H_{time_horizon}.csv' if time_horizon == 'baseline' else f'{type}_rp{rp}_24H_{time_horizon}_{ssp}.csv'\n",
    "                \n",
    "            else:\n",
    "                file = f'{type}_rp{rp}_{time_horizon}.csv' if time_horizon == 'baseline' else f'{type}_rp{rp}_{time_horizon}_{ssp}.csv'\n",
    "            \n",
    "            tmp.append(file)\n",
    "            \n",
    "\n",
    "    scenario_files.append(tmp)\n",
    "\n",
    "scenario_files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "31543880-a002-4d36-bbee-434f19c70de3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-20T09:57:05.126373Z",
     "iopub.status.busy": "2024-03-20T09:57:05.125598Z",
     "iopub.status.idle": "2024-03-20T09:57:05.218411Z",
     "shell.execute_reply": "2024-03-20T09:57:05.217851Z",
     "shell.execute_reply.started": "2024-03-20T09:57:05.126329Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create folder to store model scenario files\n",
    "\n",
    "model_path = os.path.join(root,'model_scenario_files')\n",
    "os.makedirs(model_path, exist_ok=True)\n",
    "\n",
    "model_file_path = []\n",
    "os.makedirs(model_path, exist_ok=True)\n",
    "\n",
    "# Edit config model files to change scenario files and save files\n",
    "\n",
    "res_fl = 300 # Resolution of the fluvial flood model (meters)\n",
    "res_pl = 100 # Resolution of the pluvial flood model (meters)\n",
    "\n",
    "dtmax_fl = 60 # Maximum time-step of the fluvial flood model (seconds)\n",
    "dtmax_pl = 30 # Maximum time-step of the pluvial flood model (seconds)\n",
    "\n",
    "alpha_fl = 0.5 # Limitation of CFL condition (stability)\n",
    "alpha_pl = 0.2 # Limitation of CFL condition (stability)\n",
    "\n",
    "for files, scenario in zip(scenario_files, scenarios):\n",
    "\n",
    "    model_file = configread('model.yml', abs_path=True)\n",
    "    model_file['root'] = os.path.join(root, scenario)\n",
    "    \n",
    "    model_file['region'] = (\n",
    "        os.path.join(root, 'Inputs', 'active_mask_fluvialpluvial.geojson')\n",
    "        if 'PLFL' in scenario\n",
    "        else os.path.join(root, 'Inputs', 'active_mask_fluvial.geojson')\n",
    "        if 'FL' in scenario\n",
    "        else os.path.join(root, 'Inputs', 'active_mask_pluvial.geojson')\n",
    "    )\n",
    "    \n",
    "    model_file['mask_active'] = (\n",
    "        os.path.join(root, 'Inputs', 'active_mask_fluvialpluvial.geojson')\n",
    "        if 'PLFL' in scenario\n",
    "        else (\n",
    "            os.path.join(root, 'Inputs', 'active_mask_fluvial.geojson')\n",
    "            if 'FL' in scenario\n",
    "            else os.path.join(root, 'Inputs', 'active_mask_pluvial.geojson')\n",
    "        )\n",
    "    )\n",
    "    model_file['mask_bounds'] = os.path.join(root, 'Inputs', 'outflow_fluvial.geojson') if 'FL' in scenario else os.path.join(root, 'Inputs', 'outflow_pluvial.geojson')\n",
    "    model_file['res'] = res_fl if 'fluvial' in model_file['mask_active'] else res_pl\n",
    "    model_file['dtmax'] = dtmax_fl if 'fluvial' in model_file['mask_active'] else dtmax_pl\n",
    "    model_file['ant_moist'] = 'wet'\n",
    "    model_file['alpha'] = alpha_pl if 'PL' in scenario else alpha_fl\n",
    "\n",
    "    \n",
    "    if 'PLFL' in scenario:\n",
    "        model_file['bnd'] = os.path.join(root, 'scenarios', files[1])\n",
    "        model_file['src'] = '/Users/aprida/Documents/Consulting/Private_sector/Keolis/Hydrography/ts_stations/Q_coords_allstations.geojson'\n",
    "        model_file['precip'] = os.path.join(root, 'scenarios', files[0])\n",
    "\n",
    "    elif 'FL_' in scenario:\n",
    "        model_file['bnd'] = os.path.join(root, 'scenarios', files)\n",
    "        model_file['src'] = '/Users/aprida/Documents/Consulting/Private_sector/Keolis/Hydrography/ts_stations/Q_coords_allstations.geojson'\n",
    "        model_file.pop('precip')\n",
    "        \n",
    "    elif 'PL_' in scenario:\n",
    "        model_file['precip'] = os.path.join(root, 'scenarios', files)\n",
    "        model_file.pop('bnd')\n",
    "        model_file.pop('src')\n",
    "        \n",
    "    else:\n",
    "        print('No pluvial or fluvial flood scenarios were identified.')\n",
    "\n",
    "    model_file = convert_paths_to_strings(model_file)\n",
    "    tmp_model_file_path = os.path.join(model_path, scenario + '.yml')\n",
    "    model_file_path.append(tmp_model_file_path)\n",
    "    \n",
    "    with open(tmp_model_file_path, 'w') as yaml_file:\n",
    "        yaml.dump(model_file, yaml_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "2f37aa25-289c-4d36-aa86-5330af65b699",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-20T09:57:05.815869Z",
     "iopub.status.busy": "2024-03-20T09:57:05.815528Z",
     "iopub.status.idle": "2024-03-20T09:57:05.821714Z",
     "shell.execute_reply": "2024-03-20T09:57:05.820874Z",
     "shell.execute_reply.started": "2024-03-20T09:57:05.815851Z"
    }
   },
   "outputs": [],
   "source": [
    "# Save model file paths to .txt file\n",
    "\n",
    "text_file_path = os.path.join(model_path, 'model_file_paths.txt')\n",
    "\n",
    "with open(text_file_path, 'w') as text_file:\n",
    "    for element in model_file_path:\n",
    "        text_file.write(f\"{element}\\n\")\n",
    "\n",
    "models_run_paths = os.path.join(model_path, 'models_run_paths.txt')\n",
    "\n",
    "with open(models_run_paths, 'w') as text_file:\n",
    "    for element in scenarios:\n",
    "        text_file.write(f\"{os.path.join(root, element)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac84c22-be39-4a89-b390-338de77c4714",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
